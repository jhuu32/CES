{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Feature Extractor\n",
    "this notebook generates for each text some additional/handcrafted features characterizing its named entity composition and their relative relative position (entity distance):distance is the number of words separating 2 entities (it can be negative)\n",
    "* number of sentences\n",
    "* number of words\n",
    "* distinct count of drug name entities\n",
    "* distinct count of active ingredient entities\n",
    "* count of question marks (typically to identify specifically multi-intent label)\n",
    "* individual count of interrogative pronoun entities (one column per pronoun: quand, qui, quoi, ou, comment, pourquoi, combien, quel(s|le,..)\n",
    "* distinct count of time entities (eg: jours, après midi, soir, année, 12h, mardi, samedi, temps....)\n",
    "* distinct count of quantity entities (eg: 5mg, 10ml, ...)\n",
    "* count of association entities (eg: et, avec, ou, ...)\n",
    "* distance between interrogative pronoun and drug name entities\n",
    "* distance between active ingredient and drug name entities\n",
    "* distance between quantity and drug name entities\n",
    "* distance between time and drug name entities\n",
    "* distance between question marks and drug name entities\n",
    "\n",
    "In addition, we compute the likelihood of the document to be part of the **topics identified earlier by NMF **:\n",
    "*  this probability is basically the ratio of matching top word over the total count\n",
    "\n",
    "eg: topic1 is characterized by 10 top words (A, B, C, D, ....)\n",
    "\n",
    "if the text contains words B and E, the  topic likelihood would be 2 / 10 = 1 /5\n",
    "\n",
    "these extracted features are stored into this [file](../../data/staging_data/text_extracted_features.csv) with ID column to join it with the former train dataset if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "XTrain = pd.read_csv('../../data/staging_data/mispelling_fixed_clean_input_train.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/i051796/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "def words(text):\n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "# value domain based named entities\n",
    "drugNames = set(words(open('../../data/staging_data/drug_names.txt').read()))\n",
    "ingredientNames = set(words(open('../../data/staging_data/ingredient_names.txt').read()))\n",
    "\n",
    "# reg expression based named entities\n",
    "questionMarkRegEx = r\"[\\?]+\"\n",
    "compiledquestionMarkRegEx = re.compile(questionMarkRegEx)\n",
    "\n",
    "sentenceSeparatorRegEx = r\"[\\?]+|!|:|;|[\\.]+\"\n",
    "#quiRegEx = r\"[\\s\\?\\.\\!\\:\\;]?[Q|q]ui\\s\" qui term is ambiguous\n",
    "combienRegEx = r\"[\\s\\?\\.\\!\\:\\;]?[C|c]ombien\\s\"\n",
    "pourquoiRegEx = r\"[\\s\\?\\.\\!\\:\\;]?[P|p]ourquoi\\s\"\n",
    "quandRegEx = r\"[\\s\\?\\.\\!\\:\\;]?[Q|q]uand\\s\"\n",
    "quoiRegEx = r\"[\\s\\?\\.\\!\\:\\;]?[Q|q]uoi\\s|[\\s\\?\\.\\!\\:\\;]?[Q|q]uel[l|s|le|les]?\\s\"\n",
    "commentRegEx = r\"[\\s\\?\\.\\!\\:\\;]?[C|c]omment\\s\"\n",
    "interrogativePronounRegEx = combienRegEx + '|' + pourquoiRegEx + '|' + quandRegEx + '|' + quoiRegEx + '|' + commentRegEx\n",
    "compiledPronounRegEx = re.compile(interrogativePronounRegEx)\n",
    "\n",
    "# associative entity\n",
    "ouRegEx = r\"\\sou\\s\"\n",
    "etRegEx = r\"\\set\\s\"\n",
    "avecRegEx = r\"\\savec\\s\"\n",
    "\n",
    "\n",
    "# gold standard\n",
    "timeRegEx = r\"([D|d]emain|[H|h]ier|[M|m]atin|[M|m]idi|[S|s]oir|mois|jours|[D|d]epuis|semaine[s|S]|heure[s|S])( )*( |,|\\.)\"\n",
    "quantityRegEx = r\"[0-9]+\\s?[m|k]?g|\\s[m|k]?g[^a-zA-Zéàèî]|[0-9]+\\s?[m|c]?l|\\s[m|c]?l[^a-zA-Zéàèî]\"\n",
    "\n",
    "def getWordCount(text):\n",
    "    words = word_tokenize(text, language='french')\n",
    "    return len(words)\n",
    "\n",
    "def getEntityCount(text, entityValueSet, lowerCase):\n",
    "    ''' return distinct count of entity occurrences found from the text'''\n",
    "    words = word_tokenize(text, language='french')\n",
    "    if lowerCase:\n",
    "        words = map(lambda x: x.lower(), words)\n",
    "    return len(list(set(words) & entityValueSet))\n",
    "\n",
    "def countWordsBefore(text, lastPosition):\n",
    "    ''' count number of words before this position'''\n",
    "    text = text[0:lastPosition]\n",
    "    words = word_tokenize(text, language='french')\n",
    "    return len(words)\n",
    "\n",
    "def getWordIndexByReg(text, regEx):\n",
    "    ''' return the word index of the first group matching the regexp'''\n",
    "    iterables = list(regEx.finditer(text))\n",
    "    positions = list(map(lambda x : x.span()[0], iterables))\n",
    "    if len(positions) > 0:\n",
    "        position = int(positions[0])\n",
    "        return countWordsBefore(text, position)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def getWordIndexByValueSet(text, valueSet):\n",
    "    ''' return the word index of the first token part of the value domain'''\n",
    "    words = word_tokenize(text, language='french')\n",
    "    wordIndex = 0\n",
    "    for word in words:\n",
    "        if word in valueSet:\n",
    "            return wordIndex\n",
    "        wordIndex = wordIndex + 1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain['drugCount'] = XTrain['question'].map(lambda text: getEntityCount(text, drugNames, True))\n",
    "XTrain['ingredientCount'] = XTrain['question'].map(lambda text: getEntityCount(text, ingredientNames, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain['timeCount'] = XTrain['question'].map(lambda text : len(re.findall(timeRegEx, text)))\n",
    "XTrain['quantitiesCount'] = XTrain['question'].map(lambda text : len(re.findall(quantityRegEx, text)))\n",
    "XTrain['questionMarkCount'] = XTrain['question'].map(lambda text : len(re.findall(questionMarkRegEx, text)))\n",
    "XTrain['sentenceCount'] = XTrain['question'].map(lambda text : 1 + len(re.findall(sentenceSeparatorRegEx, text)))\n",
    "XTrain['wordCount'] = XTrain['question'].map(lambda text : getWordCount(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain['combienCount'] = XTrain['question'].map(lambda text : len(re.findall(combienRegEx, text)))\n",
    "XTrain['pourquoiCount'] = XTrain['question'].map(lambda text : len(re.findall(pourquoiRegEx, text)))\n",
    "XTrain['quandCount'] = XTrain['question'].map(lambda text : len(re.findall(quandRegEx, text)))\n",
    "XTrain['quoiCount'] = XTrain['question'].map(lambda text : len(re.findall(quoiRegEx, text)))\n",
    "XTrain['commentCount'] = XTrain['question'].map(lambda text : len(re.findall(commentRegEx, text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain['avecCount'] = XTrain['question'].map(lambda text : len(re.findall(avecRegEx, text)))\n",
    "XTrain['etCount'] = XTrain['question'].map(lambda text : len(re.findall(etRegEx, text)))\n",
    "XTrain['ouCount'] = XTrain['question'].map(lambda text : len(re.findall(ouRegEx, text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain['interrogative_WordIndex'] = XTrain['question'].map(lambda text : getWordIndexByReg(text, compiledPronounRegEx))\n",
    "XTrain['questionMark_WordIndex'] = XTrain['question'].map(lambda text : getWordIndexByReg(text, compiledquestionMarkRegEx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain['drug_WordIndex'] = XTrain['question'].map(lambda text : getWordIndexByValueSet(text, drugNames))\n",
    "XTrain['drug_InterrogativeDistance'] = XTrain['interrogative_WordIndex'] - XTrain['drug_WordIndex']\n",
    "XTrain['drug_QuestionMarkDistance'] = XTrain['questionMark_WordIndex'] - XTrain['drug_WordIndex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>drugCount</th>\n",
       "      <th>ingredientCount</th>\n",
       "      <th>timeCount</th>\n",
       "      <th>quantitiesCount</th>\n",
       "      <th>questionMarkCount</th>\n",
       "      <th>sentenceCount</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>combienCount</th>\n",
       "      <th>pourquoiCount</th>\n",
       "      <th>...</th>\n",
       "      <th>quoiCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>avecCount</th>\n",
       "      <th>etCount</th>\n",
       "      <th>ouCount</th>\n",
       "      <th>interrogative_WordIndex</th>\n",
       "      <th>questionMark_WordIndex</th>\n",
       "      <th>drug_WordIndex</th>\n",
       "      <th>drug_InterrogativeDistance</th>\n",
       "      <th>drug_QuestionMarkDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  drugCount  ingredientCount  timeCount  quantitiesCount  \\\n",
       "0   0          0                1          3                0   \n",
       "1   1          1                0          0                0   \n",
       "2   2          1                0          0                0   \n",
       "3   3          1                0          0                0   \n",
       "4   4          1                1          0                0   \n",
       "\n",
       "   questionMarkCount  sentenceCount  wordCount  combienCount  pourquoiCount  \\\n",
       "0                  0              1         74             0              0   \n",
       "1                  0              1         10             0              0   \n",
       "2                  0              1         50             0              0   \n",
       "3                  0              1         14             0              0   \n",
       "4                  0              1         22             0              0   \n",
       "\n",
       "             ...              quoiCount  commentCount  avecCount  etCount  \\\n",
       "0            ...                      0             0          0        3   \n",
       "1            ...                      0             0          0        0   \n",
       "2            ...                      0             0          0        1   \n",
       "3            ...                      0             0          0        0   \n",
       "4            ...                      0             0          0        1   \n",
       "\n",
       "   ouCount  interrogative_WordIndex  questionMark_WordIndex drug_WordIndex  \\\n",
       "0        0                      NaN                    None            NaN   \n",
       "1        0                      NaN                    None            4.0   \n",
       "2        0                      NaN                    None            4.0   \n",
       "3        0                      NaN                    None           13.0   \n",
       "4        0                      NaN                    None           12.0   \n",
       "\n",
       "   drug_InterrogativeDistance  drug_QuestionMarkDistance  \n",
       "0                         NaN                       None  \n",
       "1                         NaN                       None  \n",
       "2                         NaN                       None  \n",
       "3                         NaN                       None  \n",
       "4                         NaN                       None  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\",1000)\n",
    "XTrain.drop([\"question\"], axis=1).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topic likelihood features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicTopWords = pd.read_csv('../../data/staging_data/topic_top_words.csv')\n",
    "nbTopWords = len(topicTopWords.columns) - 1\n",
    "nbTopics = len(topicTopWords)\n",
    "# build a dictionary with topic id as key and bag of top words as value\n",
    "dictOfBagTopWords = dict()\n",
    "\n",
    "for row in topicTopWords.iterrows():    \n",
    "    topic_id = row[1]['topic_id']\n",
    "    values = row[1].values\n",
    "    dictOfBagTopWords[values[0]] = set (values[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/i051796/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import textcleaner\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "frenchStopWords = set(stopwords.words(\"french\"))\n",
    "\n",
    "topicLikelihoods = []\n",
    "\n",
    "for text in XTrain.question.values:        \n",
    "    bagOfWords = set(textcleaner.cleanText(text, frenchStopWords).split())\n",
    "    topiclikelihoodRow = [None] * nbTopics\n",
    "    for topic_id, topicBagOfTopWords in dictOfBagTopWords.items():\n",
    "        matchingCount = len(bagOfWords & topicBagOfTopWords)        \n",
    "        topicLikelihoodValue = float(matchingCount)/float(nbTopWords)    \n",
    "        topiclikelihoodRow[topic_id] = topicLikelihoodValue\n",
    "    topicLikelihoods.append(topiclikelihoodRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likelihood_topic_0</th>\n",
       "      <th>likelihood_topic_1</th>\n",
       "      <th>likelihood_topic_2</th>\n",
       "      <th>likelihood_topic_3</th>\n",
       "      <th>likelihood_topic_4</th>\n",
       "      <th>likelihood_topic_5</th>\n",
       "      <th>likelihood_topic_6</th>\n",
       "      <th>likelihood_topic_7</th>\n",
       "      <th>likelihood_topic_8</th>\n",
       "      <th>likelihood_topic_9</th>\n",
       "      <th>...</th>\n",
       "      <th>likelihood_topic_41</th>\n",
       "      <th>likelihood_topic_42</th>\n",
       "      <th>likelihood_topic_43</th>\n",
       "      <th>likelihood_topic_44</th>\n",
       "      <th>likelihood_topic_45</th>\n",
       "      <th>likelihood_topic_46</th>\n",
       "      <th>likelihood_topic_47</th>\n",
       "      <th>likelihood_topic_48</th>\n",
       "      <th>likelihood_topic_49</th>\n",
       "      <th>likelihood_topic_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   likelihood_topic_0  likelihood_topic_1  likelihood_topic_2  \\\n",
       "0                0.08                 0.0                0.00   \n",
       "1                0.00                 0.0                0.00   \n",
       "2                0.02                 0.0                0.00   \n",
       "3                0.00                 0.0                0.02   \n",
       "4                0.00                 0.0                0.00   \n",
       "\n",
       "   likelihood_topic_3  likelihood_topic_4  likelihood_topic_5  \\\n",
       "0                0.02                0.02                0.02   \n",
       "1                0.00                0.00                0.00   \n",
       "2                0.00                0.00                0.00   \n",
       "3                0.00                0.02                0.00   \n",
       "4                0.00                0.02                0.00   \n",
       "\n",
       "   likelihood_topic_6  likelihood_topic_7  likelihood_topic_8  \\\n",
       "0                0.06                0.00                 0.0   \n",
       "1                0.00                0.00                 0.0   \n",
       "2                0.00                0.00                 0.0   \n",
       "3                0.00                0.02                 0.0   \n",
       "4                0.00                0.00                 0.0   \n",
       "\n",
       "   likelihood_topic_9         ...           likelihood_topic_41  \\\n",
       "0                0.02         ...                          0.02   \n",
       "1                0.00         ...                          0.00   \n",
       "2                0.00         ...                          0.00   \n",
       "3                0.00         ...                          0.00   \n",
       "4                0.00         ...                          0.02   \n",
       "\n",
       "   likelihood_topic_42  likelihood_topic_43  likelihood_topic_44  \\\n",
       "0                 0.00                  0.0                 0.00   \n",
       "1                 0.02                  0.0                 0.00   \n",
       "2                 0.00                  0.0                 0.02   \n",
       "3                 0.00                  0.0                 0.00   \n",
       "4                 0.00                  0.0                 0.00   \n",
       "\n",
       "   likelihood_topic_45  likelihood_topic_46  likelihood_topic_47  \\\n",
       "0                 0.06                 0.00                 0.02   \n",
       "1                 0.00                 0.00                 0.00   \n",
       "2                 0.00                 0.00                 0.00   \n",
       "3                 0.02                 0.02                 0.00   \n",
       "4                 0.00                 0.00                 0.00   \n",
       "\n",
       "   likelihood_topic_48  likelihood_topic_49  likelihood_topic_50  \n",
       "0                 0.04                 0.02                 0.04  \n",
       "1                 0.00                 0.00                 0.00  \n",
       "2                 0.02                 0.00                 0.02  \n",
       "3                 0.00                 0.00                 0.00  \n",
       "4                 0.00                 0.00                 0.00  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicLikelihoodFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [ 'likelihood_topic_' + str(i) for i in range(0,51)]\n",
    "topicLikelihoodFrame = pd.DataFrame(topicLikelihoods, columns = names)\n",
    "finalXTrain = XTrain.merge(topicLikelihoodFrame, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>drugCount</th>\n",
       "      <th>ingredientCount</th>\n",
       "      <th>timeCount</th>\n",
       "      <th>quantitiesCount</th>\n",
       "      <th>questionMarkCount</th>\n",
       "      <th>sentenceCount</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>combienCount</th>\n",
       "      <th>pourquoiCount</th>\n",
       "      <th>...</th>\n",
       "      <th>likelihoo_topic_41</th>\n",
       "      <th>likelihoo_topic_42</th>\n",
       "      <th>likelihoo_topic_43</th>\n",
       "      <th>likelihoo_topic_44</th>\n",
       "      <th>likelihoo_topic_45</th>\n",
       "      <th>likelihoo_topic_46</th>\n",
       "      <th>likelihoo_topic_47</th>\n",
       "      <th>likelihoo_topic_48</th>\n",
       "      <th>likelihoo_topic_49</th>\n",
       "      <th>likelihoo_topic_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  drugCount  ingredientCount  timeCount  quantitiesCount  \\\n",
       "0   0          0                1          3                0   \n",
       "1   1          1                0          0                0   \n",
       "2   2          1                0          0                0   \n",
       "3   3          1                0          0                0   \n",
       "4   4          1                1          0                0   \n",
       "\n",
       "   questionMarkCount  sentenceCount  wordCount  combienCount  pourquoiCount  \\\n",
       "0                  0              1         74             0              0   \n",
       "1                  0              1         10             0              0   \n",
       "2                  0              1         50             0              0   \n",
       "3                  0              1         14             0              0   \n",
       "4                  0              1         22             0              0   \n",
       "\n",
       "          ...          likelihoo_topic_41  likelihoo_topic_42  \\\n",
       "0         ...                        0.02                0.00   \n",
       "1         ...                        0.00                0.02   \n",
       "2         ...                        0.00                0.00   \n",
       "3         ...                        0.00                0.00   \n",
       "4         ...                        0.02                0.00   \n",
       "\n",
       "   likelihoo_topic_43  likelihoo_topic_44  likelihoo_topic_45  \\\n",
       "0                 0.0                0.00                0.06   \n",
       "1                 0.0                0.00                0.00   \n",
       "2                 0.0                0.02                0.00   \n",
       "3                 0.0                0.00                0.02   \n",
       "4                 0.0                0.00                0.00   \n",
       "\n",
       "   likelihoo_topic_46  likelihoo_topic_47 likelihoo_topic_48  \\\n",
       "0                0.00                0.02               0.04   \n",
       "1                0.00                0.00               0.00   \n",
       "2                0.00                0.00               0.02   \n",
       "3                0.02                0.00               0.00   \n",
       "4                0.00                0.00               0.00   \n",
       "\n",
       "   likelihoo_topic_49  likelihoo_topic_50  \n",
       "0                0.02                0.04  \n",
       "1                0.00                0.00  \n",
       "2                0.00                0.02  \n",
       "3                0.00                0.00  \n",
       "4                0.00                0.00  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the extraction result\n",
    "SavedTrain = finalXTrain.drop([\"question\"], axis=1)\n",
    "SavedTrain.to_csv(\"../../data/staging_data/text_extracted_features.csv\", index=None)\n",
    "SavedTrain.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
