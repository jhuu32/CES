{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Feature Extractor\n",
    "this notebook generates for each text some additional/handcrafted features characterizing its named entity composition and their relative relative position (entity distance):distance is the number of words separating 2 entities (it can be negative)\n",
    "* number of sentences\n",
    "* number of words\n",
    "* distinct count of drug name entities\n",
    "* distinct count of active ingredient entities\n",
    "* count of question marks (typically to identify specifically multi-intent label)\n",
    "* individual count of interrogative pronoun entities (one column per pronoun: quand, qui, quoi, ou, comment, pourquoi, combien, quel(s|le,..)\n",
    "* distinct count of time entities (eg: jours, après midi, soir, année, 12h, mardi, samedi, temps....)\n",
    "* distinct count of quantity entities (eg: 5mg, 10ml, ...)\n",
    "* count of association entities (eg: et, avec, ou, ...)\n",
    "* distance between interrogative pronoun and drug name entities\n",
    "* distance between active ingredient and drug name entities\n",
    "* distance between quantity and drug name entities\n",
    "* distance between time and drug name entities\n",
    "* distance between question marks and drug name entities\n",
    "\n",
    "these extracted features are stored into this [file](../../data/staging_data/text_extracted_features.csv) with ID column to join it with the former train dataset if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "XTrain = pd.read_csv('../../data/staging_data/mispelling_fixed_clean_input_train.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jacques\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "def words(text):\n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "# value domain based named entities\n",
    "drugNames = set(words(open('../../data/staging_data/drug_names.txt').read()))\n",
    "ingredientNames = set(words(open('../../data/staging_data/ingredient_names.txt').read()))\n",
    "\n",
    "# reg expression based named entities\n",
    "questionMarkRegEx = r\"[\\?]+\"\n",
    "compiledquestionMarkRegEx = re.compile(questionMarkRegEx)\n",
    "\n",
    "sentenceSeparatorRegEx = r\"[\\?]+|!|:|;|[\\.]+\"\n",
    "#quiRegEx = r\"[\\s\\?\\.\\!\\:\\;]?[Q|q]ui\\s\" qui term is ambiguous\n",
    "combienRegEx = r\"[\\s\\?\\.\\!\\:\\;]?[C|c]ombien\\s\"\n",
    "pourquoiRegEx = r\"[\\s\\?\\.\\!\\:\\;]?[P|p]ourquoi\\s\"\n",
    "quandRegEx = r\"[\\s\\?\\.\\!\\:\\;]?[Q|q]uand\\s\"\n",
    "quoiRegEx = r\"[\\s\\?\\.\\!\\:\\;]?[Q|q]uoi\\s|[\\s\\?\\.\\!\\:\\;]?[Q|q]uel[l|s|le|les]?\\s\"\n",
    "commentRegEx = r\"[\\s\\?\\.\\!\\:\\;]?[C|c]omment\\s\"\n",
    "interrogativePronounRegEx = combienRegEx + '|' + pourquoiRegEx + '|' + quandRegEx + '|' + quoiRegEx + '|' + commentRegEx\n",
    "compiledPronounRegEx = re.compile(interrogativePronounRegEx)\n",
    "\n",
    "# associative entity\n",
    "ouRegEx = r\"\\sou\\s\"\n",
    "etRegEx = r\"\\set\\s\"\n",
    "avecRegEx = r\"\\savec\\s\"\n",
    "\n",
    "\n",
    "# gold standard\n",
    "timeRegEx = r\"([D|d]emain|[H|h]ier|[M|m]atin|[M|m]idi|[S|s]oir|mois|jours|[D|d]epuis|semaine[s|S]|heure[s|S])( )*( |,|\\.)\"\n",
    "quantityRegEx = r\"[0-9]+\\s?[m|k]?g|\\s[m|k]?g[^a-zA-Zéàèî]|[0-9]+\\s?[m|c]?l|\\s[m|c]?l[^a-zA-Zéàèî]\"\n",
    "\n",
    "def getWordCount(text):\n",
    "    words = word_tokenize(text, language='french')\n",
    "    return len(words)\n",
    "\n",
    "def getEntityCount(text, entityValueSet, lowerCase):\n",
    "    ''' return distinct count of entity occurrences found from the text'''\n",
    "    words = word_tokenize(text, language='french')\n",
    "    if lowerCase:\n",
    "        words = map(lambda x: x.lower(), words)\n",
    "    return len(list(set(words) & entityValueSet))\n",
    "\n",
    "def countWordsBefore(text, lastPosition):\n",
    "    ''' count number of words before this position'''\n",
    "    text = text[0:lastPosition]\n",
    "    words = word_tokenize(text, language='french')\n",
    "    return len(words)\n",
    "\n",
    "def getWordIndexByReg(text, regEx):\n",
    "    ''' return the word index of the first group matching the regexp'''\n",
    "    iterables = list(regEx.finditer(text))\n",
    "    positions = list(map(lambda x : x.span()[0], iterables))\n",
    "    if len(positions) > 0:\n",
    "        position = int(positions[0])\n",
    "        return countWordsBefore(text, position)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def getWordIndexByValueSet(text, valueSet):\n",
    "    ''' return the word index of the first token part of the value domain'''\n",
    "    words = word_tokenize(text, language='french')\n",
    "    wordIndex = 0\n",
    "    for word in words:\n",
    "        if word in valueSet:\n",
    "            return wordIndex\n",
    "        wordIndex = wordIndex + 1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain['drugCount'] = XTrain['question'].map(lambda text: getEntityCount(text, drugNames, True))\n",
    "XTrain['ingredientCount'] = XTrain['question'].map(lambda text: getEntityCount(text, ingredientNames, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain['timeCount'] = XTrain['question'].map(lambda text : len(re.findall(timeRegEx, text)))\n",
    "XTrain['quantitiesCount'] = XTrain['question'].map(lambda text : len(re.findall(quantityRegEx, text)))\n",
    "XTrain['questionMarkCount'] = XTrain['question'].map(lambda text : len(re.findall(questionMarkRegEx, text)))\n",
    "XTrain['sentenceCount'] = XTrain['question'].map(lambda text : 1 + len(re.findall(sentenceSeparatorRegEx, text)))\n",
    "XTrain['wordCount'] = XTrain['question'].map(lambda text : getWordCount(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain['combienCount'] = XTrain['question'].map(lambda text : len(re.findall(combienRegEx, text)))\n",
    "XTrain['pourquoiCount'] = XTrain['question'].map(lambda text : len(re.findall(pourquoiRegEx, text)))\n",
    "XTrain['quandCount'] = XTrain['question'].map(lambda text : len(re.findall(quandRegEx, text)))\n",
    "XTrain['quoiCount'] = XTrain['question'].map(lambda text : len(re.findall(quoiRegEx, text)))\n",
    "XTrain['commentCount'] = XTrain['question'].map(lambda text : len(re.findall(commentRegEx, text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain['avecCount'] = XTrain['question'].map(lambda text : len(re.findall(avecRegEx, text)))\n",
    "XTrain['etCount'] = XTrain['question'].map(lambda text : len(re.findall(etRegEx, text)))\n",
    "XTrain['ouCount'] = XTrain['question'].map(lambda text : len(re.findall(ouRegEx, text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain['interrogative_WordIndex'] = XTrain['question'].map(lambda text : getWordIndexByReg(text, compiledPronounRegEx))\n",
    "XTrain['questionMark_WordIndex'] = XTrain['question'].map(lambda text : getWordIndexByReg(text, compiledquestionMarkRegEx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain['drug_WordIndex'] = XTrain['question'].map(lambda text : getWordIndexByValueSet(text, drugNames))\n",
    "XTrain['drug_InterrogativeDistance'] = XTrain['interrogative_WordIndex'] - XTrain['drug_WordIndex']\n",
    "XTrain['drug_QuestionMarkDistance'] = XTrain['questionMark_WordIndex'] - XTrain['drug_WordIndex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>drugCount</th>\n",
       "      <th>ingredientCount</th>\n",
       "      <th>timeCount</th>\n",
       "      <th>quantitiesCount</th>\n",
       "      <th>questionMarkCount</th>\n",
       "      <th>sentenceCount</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>combienCount</th>\n",
       "      <th>pourquoiCount</th>\n",
       "      <th>...</th>\n",
       "      <th>quoiCount</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>avecCount</th>\n",
       "      <th>etCount</th>\n",
       "      <th>ouCount</th>\n",
       "      <th>interrogative_WordIndex</th>\n",
       "      <th>questionMark_WordIndex</th>\n",
       "      <th>drug_WordIndex</th>\n",
       "      <th>drug_InterrogativeDistance</th>\n",
       "      <th>drug_QuestionMarkDistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  drugCount  ingredientCount  timeCount  quantitiesCount  \\\n",
       "0   0          0                1          3                0   \n",
       "1   1          1                0          0                0   \n",
       "2   2          1                0          0                0   \n",
       "3   3          1                0          0                0   \n",
       "4   4          1                1          0                0   \n",
       "\n",
       "   questionMarkCount  sentenceCount  wordCount  combienCount  pourquoiCount  \\\n",
       "0                  0              1         74             0              0   \n",
       "1                  0              1         10             0              0   \n",
       "2                  0              1         50             0              0   \n",
       "3                  0              1         14             0              0   \n",
       "4                  0              1         22             0              0   \n",
       "\n",
       "             ...              quoiCount  commentCount  avecCount  etCount  \\\n",
       "0            ...                      0             0          0        3   \n",
       "1            ...                      0             0          0        0   \n",
       "2            ...                      0             0          0        1   \n",
       "3            ...                      0             0          0        0   \n",
       "4            ...                      0             0          0        1   \n",
       "\n",
       "   ouCount  interrogative_WordIndex  questionMark_WordIndex drug_WordIndex  \\\n",
       "0        0                      NaN                    None            NaN   \n",
       "1        0                      NaN                    None            4.0   \n",
       "2        0                      NaN                    None            4.0   \n",
       "3        0                      NaN                    None           13.0   \n",
       "4        0                      NaN                    None           12.0   \n",
       "\n",
       "   drug_InterrogativeDistance  drug_QuestionMarkDistance  \n",
       "0                         NaN                       None  \n",
       "1                         NaN                       None  \n",
       "2                         NaN                       None  \n",
       "3                         NaN                       None  \n",
       "4                         NaN                       None  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\",1000)\n",
    "XTrain.drop([\"question\"], axis=1).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the extraction result\n",
    "SavedTrain = XTrain.drop([\"question\"], axis=1)\n",
    "SavedTrain.to_csv(\"../../data/staging_data/text_extracted_features.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
